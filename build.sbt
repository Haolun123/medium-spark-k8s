import sbt.Def

val dependencyScope = sys.props.getOrElse("sparkDependencyScope", default = "compile")

val sparkVersion = "2.4.4"
val scalaTestVersion = "3.0.7"

val scalaMainVersion = "2.12.8"


val sparkLibs = Seq(
  "org.apache.spark" %% "spark-core" % sparkVersion % dependencyScope,
  "org.apache.spark" %% "spark-sql" % sparkVersion % dependencyScope
)

val testingLibs = Seq(
  "org.scalatest" %% "scalatest" % scalaTestVersion % Test
)

// Settings
val team = "graphiq"
val importerDescription = "Sample ETL Job for Medium Post"
val importerMainClass = "xyz.graphiq.BasicSparkJob"
val targetDockerJarPath = "/opt/spark/jars"

lazy val commonSettings = Seq(
  organization := "xyz.graphiq",
  scalaVersion := scalaMainVersion,
  version ~= (_.replace('+', '-')),
  dynver ~= (_.replace('+', '-')),
  libraryDependencies ++= sparkLibs ++ testingLibs,
  scalacOptions ++= Seq(
    "-deprecation",
    "-unchecked",
    "-Xlint",
    "-Xlint:missing-interpolator",
    "-Ywarn-unused",
    "-Ywarn-dead-code",
    "-language:_",
    "-encoding", "UTF-8"
  )
)

lazy val testSettings = Seq(
  Test / testOptions += Tests.Argument("-oDT"),
  Test / parallelExecution := false
)

lazy val assemblySettings = Seq(
  // Assembly options
  assembly / assemblyOption := (assemblyOption in assembly).value.copy(includeScala = false),
  assembly / assemblyOutputPath := baseDirectory.value / "../output" / s"${team}-${name.value}.jar",
  assembly / assemblyMergeStrategy := {
    case PathList("reference.conf") => MergeStrategy.concat
    case PathList("META-INF", _@_*) => MergeStrategy.discard
    case "log4j.properties" => MergeStrategy.concat
    case _ => MergeStrategy.first
  },
  assembly / logLevel := sbt.util.Level.Error,
  assembly / test := {},
  pomIncludeRepository := { _ => false }
)


lazy val dockerSettings = Seq(
  imageNames in docker := Seq(
    ImageName(s"$team/${name.value}:latest"),
    ImageName(s"$team/${name.value}:${version.value}"),
  ),
  buildOptions in docker := BuildOptions(
    cache = false,
    removeIntermediateContainers = BuildOptions.Remove.Always,
    pullBaseImage = BuildOptions.Pull.Always
  ),
  dockerfile in docker := {
    // The assembly task generates a fat JAR file
    val artifact: File = assembly.value
    val artifactTargetPath = s"$targetDockerJarPath/$team-${name.value}.jar"
      new Dockerfile {
        from(s"localhost:5000/spark-runner")
      }.add(artifact, artifactTargetPath)
  }
)

lazy val base = (project in file("."))
  .enablePlugins(JavaAppPackaging)
  .enablePlugins(sbtdocker.DockerPlugin)
  .enablePlugins(AshScriptPlugin)
  .settings(
    commonSettings,
    testSettings,
    assemblySettings,
    dockerSettings,
    name := "etl-importer",
    Compile / mainClass := Some(importerMainClass),
    Compile / resourceGenerators += createImporterHelmChart.taskValue
  )

lazy val createImporterHelmChart: Def.Initialize[Task[Seq[File]]] = Def.task {
  val chartFile = baseDirectory.value / "../helm" / "Chart.yaml"
  val valuesFile = baseDirectory.value / "../helm" / "values.yaml"
  
  val chartContents =
    s"""# Generated by build.sbt. Please don't manually update
       |apiVersion: v1
       |name: $team-${name.value}
       |version: ${version.value}
       |appVersion: ${version.value}
       |description: $importerDescription
       |keywords:
       |  - Spark
       |  - ETL
       |  - Medium
       |  - Kubernetes
       |  - Helm
       |  - Spark Operator
       |home: [url to post]
       |sources:
       |  - https://github.com/TomLous/medium-spark-k8s
       |maintainers: 
       |  - name: Tom Lous
       |    email: tomlous@gmail.com
       |    url: https://lous.info       
       |""".stripMargin

  val valuesContents =
    s"""# Generated by build.sbt. Please don't manually update      
       |version: ${version.value}
       |sparkVersion: $sparkVersion
       |image: IMAGE_REGISTRY_URL/$team/${name.value}:${version.value}
       |jar: local://$targetDockerJarPath/$team-${name.value}.jar
       |mainClass: $importerMainClass
       |fileDependencies: []
       |""".stripMargin

  IO.write(chartFile, chartContents)
  IO.write(valuesFile, valuesContents)
  Seq(chartFile, valuesFile)
}